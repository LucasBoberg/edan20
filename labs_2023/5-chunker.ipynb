{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #4: Extracting syntactic groups using recurrent networks\n",
    "Author: Pierre Nugues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will create a system to extract syntactic groups from a text. You will apply it to the CoNLL 2000 dataset. You will train your models with PyTorch.\n",
    "\n",
    "Be aware that in PyTorch, the data matrices, by default, have an unconventional ordering with recurrent networks. To have a batch ordering similar to what we saw during the course, you must use the `batch_first=True` argument. See here https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html and https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "\n",
    "Before you start the assignment, please run the prerequisites from the prerequistites notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to detect partial syntactic structures called groups or chunks\n",
    "* Understand the principles of supervised machine learning techniques applied to language processing\n",
    "* Write a short report of 2 to 3 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This instruction may solve installation conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import conlleval\n",
    "torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "Making things reproduceable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10fab32f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "LSTM_HIDDEN_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the paths to load the datasets from your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'corpus/train.txt'\n",
    "test_file = 'corpus/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now convert the dataset in a Python data structure. Read the functions below to load the datasets. They store the corpus in a list of sentences. Each sentence is a list of rows, where each row is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file).read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, row.split())) for row in rows]\n",
    "        new_sentences.append(sentence)\n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL 2000 files have three columns: The wordform, `form`, its part of speech, `pos`, and the tag denoting the syntactic group also called the chunk tag, `chunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the corpus as a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'He', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'reckons', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'current', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'account', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'deficit', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'will', 'pos': 'MD', 'chunk': 'B-VP'},\n",
       "  {'form': 'narrow', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-PP'},\n",
       "  {'form': 'only', 'pos': 'RB', 'chunk': 'B-NP'},\n",
       "  {'form': '#', 'pos': '#', 'chunk': 'I-NP'},\n",
       "  {'form': '1.8', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'billion', 'pos': 'CD', 'chunk': 'I-NP'},\n",
       "  {'form': 'in', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'September', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = read_sentences(train_file)\n",
    "train_dict = split_rows(train_sentences, column_names)\n",
    "train_dict[10:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'corpus.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the function below that reads GloVe embeddings and store them in a dictionary, where the keys will be the words and the values, the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "    \"\"\"\n",
    "    Return the embeddings in the from of a dictionary\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    glove = open(file, encoding='utf8')\n",
    "    for line in glove:\n",
    "        values = line.strip().split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        embeddings[word] = vector\n",
    "    glove.close()\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the embeddings\n",
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# words in embedding dictionary: 400000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'# words in embedding dictionary: {}'.format(len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chording',\n",
       " 'chordoma',\n",
       " 'chordophones',\n",
       " 'chords',\n",
       " 'chore',\n",
       " 'chorea',\n",
       " 'chorene',\n",
       " 'choreograph',\n",
       " 'choreographed',\n",
       " 'choreographer']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words[100000:100010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.51973,  1.0395 ,  0.20924,  0.16285,  0.7209 ,  0.81524,\n",
       "       -0.34641, -0.76654, -0.49576,  0.24634,  0.44094,  0.37701,\n",
       "       -0.16396,  0.2775 ,  0.16563,  0.43869, -1.0887 ,  0.12663,\n",
       "        0.66916,  0.3578 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['chords'][:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a cosine similarity, write a `closest(target_word, embeddings, count=10)` that computes the 10 closest words to the words _table_, _france_, and _sweden_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def cosine_sim(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def closest2(target_word, embeddings, count=10): \n",
    "    target_vector = embeddings[target_word]\n",
    "    distances = [(word, cosine_sim(target_vector, embeddings[word])) for word in embeddings.keys()]\n",
    "    distances.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [word[0] for word in distances[:count]]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['france',\n",
       " 'belgium',\n",
       " 'french',\n",
       " 'britain',\n",
       " 'spain',\n",
       " 'paris',\n",
       " 'germany',\n",
       " 'italy',\n",
       " 'europe',\n",
       " 'netherlands']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('france', embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sweden',\n",
       " 'denmark',\n",
       " 'norway',\n",
       " 'finland',\n",
       " 'netherlands',\n",
       " 'austria',\n",
       " 'switzerland',\n",
       " 'germany',\n",
       " 'swedish',\n",
       " 'belgium']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest2('sweden', embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the ${X}$ and ${Y}$ Lists of Symbols from the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each sentence, you will build an input sequence, $\\mathbf{x}$, corresponding to the words and an output one, $\\mathbf{y}$, corresponding to the chunk tags.\n",
    "\n",
    "Write a `build_sequences(corpus_dict, key_x='form', key_y='chunk', tolower=True)` function that, for each sentence, returns the $\\mathbf{x}$ and $\\mathbf{y}$ lists of symbols consisting of words and chunk tags. Set the words in lower case if `tolower` is true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 11th sentence of the training set, you should have:<br/>\n",
    "`x = ['he',  'reckons',  'the',  'current',  'account',  'deficit',  'will',  'narrow',  'to',  'only',  '#',  '1.8',  'billion',  'in',  'september',  '.']`\n",
    "\n",
    "`y = ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def build_sequences(corpus_dict, key_x='form', key_y='pos', tolower=True):\n",
    "    \"\"\"\n",
    "    Creates sequences from a list of dictionaries\n",
    "    :param corpus_dict:\n",
    "    :param key_x:\n",
    "    :param key_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    for sentence in corpus_dict:\n",
    "        x = []\n",
    "        y = []\n",
    "        for word in sentence:\n",
    "            x.append(word[key_x].lower() if tolower else word[key_x])\n",
    "            y.append(word[key_y])\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_symbs, Y_train_symbs = build_sequences(train_dict, key_x='form', key_y='chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'reckons', 'the', 'current', 'account', 'deficit', 'will', 'narrow', 'to', 'only', '#', '1.8', 'billion', 'in', 'september', '.']\n"
     ]
    }
   ],
   "source": [
    "print(X_train_symbs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_symbs[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a vocabulary of all the words observed in the training set as well as in GloVe. You should find 401,464 different words. You will proceed in two steps.\n",
    "\n",
    "First extract the list of unique words `words` from the CoNLL training set and the list of chunk tags, `chunks`. You will sort them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: List of words and tags in CoNLL\n",
    "words_set = set()\n",
    "chunks_set = set()\n",
    "for sentence in train_dict:\n",
    "    for word in sentence:\n",
    "        words_set.add(word['form'].lower())\n",
    "        chunks_set.add(word['chunk'])\n",
    "\n",
    "words = sorted(list(words_set))\n",
    "chunks = sorted(list(chunks_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words seen in training corpus: 17258\n",
      "# Chunks tags seen: 22\n"
     ]
    }
   ],
   "source": [
    "print('# words seen in training corpus:', len(words))\n",
    "print('# Chunks tags seen:', len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['casinos',\n",
       " 'caspita',\n",
       " 'caspita-brand',\n",
       " 'cassettes',\n",
       " 'cast',\n",
       " 'castigated',\n",
       " 'castigating',\n",
       " 'castillo',\n",
       " 'casting',\n",
       " 'castro-medellin']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[4000:4010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-ADJP',\n",
       " 'B-ADVP',\n",
       " 'B-CONJP',\n",
       " 'B-INTJ',\n",
       " 'B-LST',\n",
       " 'B-NP',\n",
       " 'B-PP',\n",
       " 'B-PRT',\n",
       " 'B-SBAR',\n",
       " 'B-UCP']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, merge the list of unique CoNLL words with the words in the embeddings file. You will sort this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code: Add vocabulary of embedded words\n",
    "vocabulary_words = sorted(list(set(words + embedded_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# words in the vocabulary: embeddings and corpus: 401464\n"
     ]
    }
   ],
   "source": [
    "print('# words in the vocabulary: embeddings and corpus:', len(vocabulary_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy',\n",
       " 'joya',\n",
       " 'joyal',\n",
       " 'joyandet',\n",
       " 'joyas',\n",
       " 'joyce',\n",
       " 'joycean',\n",
       " 'joycelyn',\n",
       " 'joyces',\n",
       " 'joydeep']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_words[200000:200010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the indices `word2idx`, `chunk2idx` and inverted indices `idx2word`, `idx2chunk` for the words and the chunk tags: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words. This means that your first word will start at index 2. For the chunks, you will start at index 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code:\n",
    "idx2word = {idx: word for idx, word in enumerate(vocabulary_words, 2)}\n",
    "idx2chunk = {idx: chunk for idx, chunk in enumerate(chunks, 1)}\n",
    "word2idx = {word: idx for idx, word in idx2word.items()}\n",
    "chunk2idx = {chunk: idx for idx, chunk in idx2chunk.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('!', 2), ('!!', 3), ('!!!', 4), ('!!!!', 5), ('!!!!!', 6), ('!?', 7), ('!?!', 8), ('\"', 9), ('#', 10), ('##', 11), ('###', 12), ('#a', 13), ('#aabccc', 14), ('#b', 15), ('#c', 16), ('#cc', 17), ('#ccc', 18), ('#cccccc', 19), ('#ccccff', 20), ('#d', 21), ('#daa', 22), ('#dcdcdc', 23), ('#e', 24), ('#f', 25), ('#faf', 26)]\n"
     ]
    }
   ],
   "source": [
    "print(list(word2idx.items())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chunk indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-ADJP': 1, 'B-ADVP': 2, 'B-CONJP': 3, 'B-INTJ': 4, 'B-LST': 5, 'B-NP': 6, 'B-PP': 7, 'B-PRT': 8, 'B-SBAR': 9, 'B-UCP': 10, 'B-VP': 11, 'I-ADJP': 12, 'I-ADVP': 13, 'I-CONJP': 14, 'I-INTJ': 15, 'I-NP': 16, 'I-PP': 17, 'I-PRT': 18, 'I-SBAR': 19, 'I-UCP': 20, 'I-VP': 21, 'O': 22}\n"
     ]
    }
   ],
   "source": [
    "print(chunk2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a numpy matrix of dimensions $(M, N)$, where $M$ will be the size of the vocabulary: The unique words in the training set and the words in GloVe, and $N$, the dimension of the embeddings.\n",
    "The padding symbol and the unknown word symbol will be part of the vocabulary at respectively index 0 and 1. \n",
    "\n",
    "Initialize the matrix with random values with the `np.random.uniform()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add two dimensions for the padding symbol at index 0 and unknown words at index 1\n",
    "embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.random.random((len(vocabulary_words) + 2, EMBEDDING_DIM))\n",
    "# embedding_matrix = np.zeros((len(vocabulary_words) + 2, EMBEDDING_DIM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of your matrix is: (401466, 100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(401466, 100)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill the matrix with the GloVe embeddings when available. This means: Replace the random vector with an embedding when available. You will use the indices from the previous section. You will call `out_of_embeddings` the list of words in CoNLL, but not in the embedding list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "out_of_embeddings = []\n",
    "for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "        embedding_matrix[word2idx[word]] = embeddings_dict[word]\n",
    "    else:\n",
    "        out_of_embeddings.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1464"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_of_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"y'all\",\n",
       " 'yankus',\n",
       " 'year-ago',\n",
       " 'year-before',\n",
       " 'year-earlier',\n",
       " 'year-to-date',\n",
       " 'yield-management',\n",
       " 'zaishuo',\n",
       " 'zarett',\n",
       " 'zumbrunn']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_of_embeddings[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the padding symbol, idx 0, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03084805,  0.01221088, -0.00622723,  0.02853586,  0.02799758,\n",
       "       -0.02274074, -0.02235357,  0.03018722,  0.04581394,  0.03759326])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of the word _table_, the GloVe values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.61453998,  0.89692998,  0.56770998,  0.39102   , -0.22437   ,\n",
       "        0.49035001,  0.10868   ,  0.27410999, -0.23833001, -0.52152997])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['table']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings of _zarett_, a word in CoNLL 2000, but not in GloVe, random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04485961, -0.01950363,  0.03356147, -0.02404349, -0.04000838,\n",
       "        0.01959841, -0.03943566, -0.01355046,  0.00896135, -0.02441297])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word2idx['zarett']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ${X}$ and ${Y}$ Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now create the input and output sequences with numerical indices. First, convert the \n",
    "${X}_\\text{train\\_symbs}$ and ${Y}_\\text{train\\_symbs}$ \n",
    "lists of symbols in lists of numbers using the indices you created. Call them `X_train_idx` and `Y_train_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# We create the parallel sequences of indexes\n",
    "X_train_idx = []\n",
    "Y_train_idx = []\n",
    "for x, y in zip(X_train_symbs, Y_train_symbs):\n",
    "    x_idx = [word2idx.get(word.lower(), 1) for word in x]\n",
    "    y_idx = [chunk2idx.get(chunk, 0) for chunk in y]\n",
    "    X_train_idx.append(x_idx)\n",
    "    Y_train_idx.append(y_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[107701, 189360, 358640, 291209, 193879, 388606, 143496, 362305, 353285, 56501, 328878, 126632, 187522, 364843, 148777, 152124, 326524, 454, 131007, 152124, 306232, 363097, 454, 144953, 362305, 331257, 43426, 347508, 189267, 155109, 200552, 55175, 63614, 154, 259236, 120001, 873], [97171, 269136, 358640, 143112, 262191, 219534, 154, 307829, 106548, 362305, 43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204, 43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150, 873], [88319, 54890, 304156, 372747, 349558, 152124, 344283, 174855, 72318, 139858, 88675, 358640, 97171, 154, 144970, 362305, 56361, 57639, 261034, 288933, 240241, 189360, 180283, 234487, 183252, 340448, 218722, 360423, 873]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk tag indices of the three first sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 6, 16, 11, 21, 21, 21, 21, 6, 16, 16, 9, 6, 16, 7, 6, 22, 1, 7, 6, 6, 22, 11, 21, 21, 6, 16, 16, 7, 6, 16, 16, 6, 16, 16, 22], [22, 7, 6, 16, 6, 16, 6, 16, 16, 7, 6, 16, 16, 16, 11, 21, 21, 21, 6, 16, 7, 6, 7, 6, 16, 16, 22], [22, 6, 11, 6, 16, 7, 6, 11, 21, 21, 7, 6, 16, 6, 16, 11, 21, 6, 16, 16, 16, 7, 6, 16, 16, 16, 6, 16, 22]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train_idx[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pad the sentences using the `pad_sequences` function. After padding, the second sentence you look like (the indices are not necessarily the same).\n",
    "```\n",
    "x = [ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
    "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
    "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
    "             0,      0,      0,      0,      0,      0]\n",
    "y = [22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
    "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "         0,  0,  0,  0,  0,  0]\n",
    "```\n",
    "\n",
    "You will call the results `X_train_padded` and `Y_train_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_idx = list(map(torch.LongTensor, X_train_idx))\n",
    "Y_train_idx = list(map(torch.LongTensor, Y_train_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "X_train_padded = pad_sequence(X_train_idx, batch_first=True)\n",
    "Y_train_padded = pad_sequence(Y_train_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 97171, 269136, 358640, 143112, 262191, 219534,    154, 307829, 106548,\n",
       "        362305,  43426, 149626, 249511, 288933, 174855, 177388, 362305, 293204,\n",
       "         43426, 154301, 189360, 344283, 274536, 358640, 279589, 386150,    873,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "             0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([22,  7,  6, 16,  6, 16,  6, 16, 16,  7,  6, 16, 16, 16, 11, 21, 21, 21,\n",
       "         6, 16,  7,  6,  7,  6, 16, 16, 22,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_padded[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your network consisting of one embedding layer, a simple recurrent neural network, either RNN or LSTM, and a linear layer. You will initialize the embedding layer with `embedding_matrix` using `from_pretrained()`. You may try other configurations after. As number of RNN/LSTM units use 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_matrix, embedding_dim, lstm_units, nbr_classes, bidi_lstm=False):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_units = lstm_units\n",
    "        self.embeddings = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False, padding_idx=0)\n",
    "        self.nbr_classes = nbr_classes\n",
    "        self.bidi_lstm = bidi_lstm        \n",
    "        self.lstm = nn.LSTM(self.embedding_dim, self.lstm_units, bidirectional=self.bidi_lstm, batch_first=True)\n",
    "        self.linear = nn.Linear(self.lstm_units * (2 if self.bidi_lstm else 1), self.nbr_classes)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeddings = self.embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        logits = self.linear(lstm_out)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(embedding_matrix, EMBEDDING_DIM, LSTM_HIDDEN_DIM, len(chunks) + 1, bidi_lstm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embeddings): Embedding(401466, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 128, batch_first=True, bidirectional=True)\n",
       "  (linear): Linear(in_features=256, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the loss `loss_fn` and optimizer `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.LongTensor(X_train_padded)\n",
    "Y_train = torch.LongTensor(Y_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Few Experiments\n",
    "Flattening the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 6,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.view(-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8936, 78, 23])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([697008, 23])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_pred.view(-1, Y_train_pred.size()[-1]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to store the accuracy and the loss. Th exact values are difficult to compute because of the padding symbols. We include the padding symbols in the computation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "history['accuracy'] = []\n",
    "history['loss'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:54<00:00,  5.16it/s]\n",
      "100%|██████████| 280/280 [00:51<00:00,  5.42it/s]\n",
      "100%|██████████| 280/280 [00:47<00:00,  5.88it/s]\n",
      "100%|██████████| 280/280 [00:46<00:00,  6.06it/s]\n",
      "100%|██████████| 280/280 [00:46<00:00,  6.04it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.32it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.33it/s]\n",
      "100%|██████████| 280/280 [00:45<00:00,  6.21it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.25it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.34it/s]\n",
      "100%|██████████| 280/280 [00:45<00:00,  6.15it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.33it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.34it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.22it/s]\n",
      "100%|██████████| 280/280 [00:44<00:00,  6.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    word_cnt = 0\n",
    "    batch_cnt = 0\n",
    "    for X_batch, Y_batch in tqdm(dataloader):\n",
    "        batch_cnt += 1\n",
    "        Y_batch_pred = model1(X_batch)\n",
    "        loss = loss_fn(Y_batch_pred.view(-1, Y_batch_pred.shape[-1]), Y_batch.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_accuracy += torch.sum(torch.argmax(model1(X_train), dim=-1) == Y_train)\n",
    "    history['accuracy'] += [train_accuracy/torch.numel(Y_train)]\n",
    "    history['loss'] += [train_loss/batch_cnt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we visualize the training curves. Ideally, we would compare them with a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history['accuracy']\n",
    "loss = history['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.title('Training accuracies')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training losses')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the model on a test sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'The United States might collapsez .'.lower().split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the sentence words to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "# The indexes or the unknown word idx\n",
    "sentence_word_idxs = [word2idx.get(word, 1) for word in sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices. Note the 1 at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence ['the', 'united', 'states', 'might', 'collapsez', '.']\n",
      "Sentence word indexes [358640, 373606, 343335, 245002, 1, 873]\n"
     ]
    }
   ],
   "source": [
    "print('Sentence', sentence)\n",
    "print('Sentence word indexes', sentence_word_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the variable `sent_chunk_predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "sent_chunk_predictions = torch.argmax(model1(torch.LongTensor(sentence_word_idxs).unsqueeze(1)), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 23])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_chunk_predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated probabilities of the first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"softmax_lastdim_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/lucas/Developer/python/edan20/labs_2023/5-chunker.ipynb Cell 126\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lucas/Developer/python/edan20/labs_2023/5-chunker.ipynb#Y236sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m F\u001b[39m.\u001b[39msoftmax(sent_chunk_predictions[\u001b[39m0\u001b[39m], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:1843\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     dim \u001b[39m=\u001b[39m _get_softmax_dim(\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1842\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim)\n\u001b[1;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msoftmax(dim, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"softmax_lastdim_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "F.softmax(sent_chunk_predictions[0], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(F.softmax(sent_chunk_predictions, dim=-1), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply argmax to select the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: B-NP\n",
      "united: I-NP\n",
      "states: I-NP\n",
      "might: B-VP\n",
      "collapsez /ukn: I-VP\n",
      ".: O\n"
     ]
    }
   ],
   "source": [
    "for word_nbr, chunk_predictions in enumerate(sent_chunk_predictions):\n",
    "    if int(sentence_word_idxs[word_nbr]) in idx2word:\n",
    "        print(idx2word[int(sentence_word_idxs[word_nbr])], end=': ')\n",
    "    else:\n",
    "        print(sentence[word_nbr], '/ukn', end=': ')\n",
    "    print(idx2chunk.get(int(torch.argmax(F.softmax(chunk_predictions, dim=-1), dim=-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP'},\n",
       "  {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP'},\n",
       "  {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR'},\n",
       "  {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP'},\n",
       "  {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP'},\n",
       "  {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP'},\n",
       "  {'form': '200', 'pos': 'CD', 'chunk': 'B-NP'},\n",
       "  {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP'},\n",
       "  {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP'},\n",
       "  {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP'},\n",
       "  {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP'},\n",
       "  {'form': '.', 'pos': '.', 'chunk': 'O'}]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences = read_sentences(test_file)\n",
    "test_dict = split_rows(test_sentences, column_names)\n",
    "test_dict[1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the ${X}$ and ${Y}$ sequences of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test: ['rockwell', 'said', 'the', 'agreement', 'calls', 'for', 'it', 'to', 'supply', '200', 'additional', 'so-called', 'shipsets', 'for', 'the', 'planes', '.']\n",
      "Y_test ['B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "X_test_symbs, Y_test_symbs = build_sequences(test_dict, key_x='form', key_y='chunk')\n",
    "print('X_test:', X_test_symbs[1])\n",
    "print('Y_test', Y_test_symbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the ${X}$ symbol sequence into an index sequence and pad it. Call the results `X_test_idx` and `X_test_padded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "X_test_idx = []\n",
    "for x in X_test_symbs:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_idx = map(torch.LongTensor, X_test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_padded = pad_sequence(X_test_idx, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_padded: tensor([311438, 316957, 358640,  48789,  90494, 152124, 194623, 362305, 349553,\n",
      "         17495,  46648, 337426,      1, 152124, 358640, 287224,    873,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "print('X_test_padded:', X_test_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2012, 70])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the chunks. Call the result `Y_test_hat_probs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "Y_test_hat_probs = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions tensor([[ -7.0167,  -1.3971,  -2.6404,  ...,  -1.0799,  -1.3150,   4.7549],\n",
      "        [ -6.5066,  -4.5663,   1.0363,  ...,  -2.3344,   6.9481,   6.8664],\n",
      "        [-11.6368,  -2.9430,  -2.0845,  ...,  -4.6665,  -7.5087,   6.0453],\n",
      "        ...,\n",
      "        [ 20.2845,  -4.0088,  -3.6083,  ...,  -1.0157,  -5.1971,   0.3017],\n",
      "        [ 18.3593,  -3.3927,  -3.4281,  ...,  -0.7486,  -4.9716,  -0.0463],\n",
      "        [ 16.9232,  -2.7952,  -3.0611,  ...,  -0.5927,  -4.9505,  -0.2680]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print('Predictions', Y_test_hat_probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_hat_probs = F.softmax(Y_test_hat_probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now predict the whole test set and we store the results in each dictionary with the key `pchunk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, y_hat_probs in zip(test_dict, Y_test_hat_probs):\n",
    "    sent_len = len(sent)\n",
    "    y_hat_probs = y_hat_probs[:sent_len]\n",
    "    # y_hat = torch.argmax(y_hat_probs, dim=-1) # This statement sometimes predicts 0 (the padding symbol)\n",
    "    y_hat = torch.argmax(y_hat_probs[:, 1:], dim=-1) + 1 # Never predicts 0\n",
    "    for word, ner_hat in zip(sent, y_hat):\n",
    "        word['pchunk'] = idx2chunk.get(int(ner_hat)) \n",
    "        if word['pchunk'] == None:\n",
    "            print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence example: `chunk` is the hand annotation and `pchunk` is the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': 'Rockwell', 'pos': 'NNP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'said', 'pos': 'VBD', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'agreement', 'pos': 'NN', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'calls', 'pos': 'VBZ', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-SBAR', 'pchunk': 'B-PP'},\n",
       " {'form': 'it', 'pos': 'PRP', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'to', 'pos': 'TO', 'chunk': 'B-VP', 'pchunk': 'B-VP'},\n",
       " {'form': 'supply', 'pos': 'VB', 'chunk': 'I-VP', 'pchunk': 'I-VP'},\n",
       " {'form': '200', 'pos': 'CD', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'additional', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'so-called', 'pos': 'JJ', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'shipsets', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': 'for', 'pos': 'IN', 'chunk': 'B-PP', 'pchunk': 'B-PP'},\n",
       " {'form': 'the', 'pos': 'DT', 'chunk': 'B-NP', 'pchunk': 'B-NP'},\n",
       " {'form': 'planes', 'pos': 'NNS', 'chunk': 'I-NP', 'pchunk': 'I-NP'},\n",
       " {'form': '.', 'pos': '.', 'chunk': 'O', 'pchunk': 'O'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the test set in a file to evaluate the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['form', 'pos', 'chunk', 'pchunk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, column_names):\n",
    "    \"\"\"\n",
    "    Saves the corpus in a file\n",
    "    :param file:\n",
    "    :param corpus_dict:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        i += 1\n",
    "        for sentence in corpus_dict:\n",
    "            sentence_lst = []\n",
    "            for row in sentence:\n",
    "                items = map(lambda x: row.get(x, '_'), column_names)\n",
    "                sentence_lst += ' '.join(items) + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = 'test_model1.out'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(outfile, test_dict, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9000020716372148"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open(outfile, encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "chunker_score = res['overall']['chunks']['evals']['f1']\n",
    "chunker_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may slightly vary depending on the run\n",
    "# 0.8650974227443842 lstm nontrainable 15 epochs\n",
    "# 0.8579701751845953 lstm trainable 15 epochs\n",
    "# 0.9015216169521867 lstm bidi nontrainable 15 epochs\n",
    "# 0.9000310655483068 lstm bidi trainable 15 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out experiments with two different recurrent networks: RNN and LSTM. You will also try at least one set of parameters per network, i.e. two experiments, one with a RNN and one with a LSTM. To run a RNN, just replace the LSTM class with RNN. As baseline, a simple solution you consider a starting point, please report the baseline figures from CoNLL 2000: https://aclanthology.org/W00-0726.pdf. \n",
    "\n",
    "In your report, you will present your results in a table like this one:\n",
    "\n",
    "|Method|Parameters|Score|\n",
    "|------|-----|-----|\n",
    "|Baseline|  xx | xx |\n",
    "|RNN|  xx |xx |\n",
    "|RNN |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|LSTM |  xx |xx |\n",
    "|  Akbik et al.|  xx|xx |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning in your assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your are done with the program. To complete this assignment, you will:\n",
    "1. Write a short individual report on your program. You will describe the architecture your used the different experiments you carried out and your results.\n",
    "2. Read the article, <a href=\"https://www.aclweb.org/anthology/C18-1139\"><i>Contextual String Embeddings for Sequence Labeling</i></a> by Akbik et al. (2018) and outline the main differences between their system and yours. A LSTM is a type of recurrent neural network, while CRF is a sort of beam search. You will tell the performance they reach on the corpus you used in this laboratory.\n",
    "\n",
    "Submit your report as well as your notebook (for archiving purposes) to Canvas: https://canvas.education.lu.se/. To write your report, you can either\n",
    "1. Write directly your text in Canvas, or\n",
    "2. Use Latex and Overleaf (www.overleaf.com). This will probably help you structure your text. You will then upload a PDF file in Canvas.\n",
    "\n",
    "The submission deadline is October 13, 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b97b11a820675205aae8f1d7f2a3f22bbd3a2c30189f44042310baf5b4cd1987"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
